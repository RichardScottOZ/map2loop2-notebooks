{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc399bd7",
   "metadata": {},
   "source": [
    "## Example codes for converting surface and voxel model to different formats and extract information from loop gml file\n",
    "\n",
    " - The surface conversion codes assume that a directory of obj format surfaces already exsists, which will exsist if using any of the example notebooks, and the code can be run directly from this notebook simply by updating the file paths\n",
    " - The voxel conversion codes need to be pasted at the end of the one of the Example notebooks as it relies on having access to a LoopStructural model object.\n",
    " - The loop.gml file combines all the disparate outputs from map2loop into a single graph which may be queried to retreive the indiivdual satasets, or to analyse topology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07d7ff7",
   "metadata": {},
   "source": [
    "## Convert geotif of dtm to obj format mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2acb1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from map2loop.m2l_utils import save_dtm_mesh\n",
    "obj_path_dir='D:/Dropbox/1_Jupyter_notebooks/Peak_District/Peak_District_out_07/dtm/'   # directory of obj surfaces\n",
    "dtm_path='D:/Dropbox/1_Jupyter_notebooks/Peak_District/Peak_District_out_07/dtm/'  # directory of existing geotif dtm\n",
    "save_dtm_mesh(dtm_path,obj_path_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bdeb7f",
   "metadata": {},
   "source": [
    "### GeoscienceAnalyst geohy5 format surfaces from directory of obj files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49380d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to parse a directory of .obj files and combine them into\n",
    "#a single geoh5 file that GeoscienceAnalyst can read\n",
    "#Requires installation of https://github.com/MiraGeoscience/geoh5py \n",
    "#(note .geoh5 meshes are 0 based)\n",
    "#Run this code after obj files have been created (see Example notebooks)\n",
    "\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from geoh5py.objects import BlockModel\n",
    "from geoh5py.workspace import Workspace\n",
    "from geoh5py.objects import Surface\n",
    "import omf\n",
    "\n",
    "def hextofloats(h):\n",
    "    '''Takes a hex rgb string (e.g. #ffffff) and returns an RGB tuple (float, float, float).'''\n",
    "    return tuple(int(h[i:i + 2], 16) / 255. for i in (1, 3, 5))  # skip '#'\n",
    "\n",
    "def geoh5_create_surface_data(obj_path_dir,colour_path):\n",
    "\n",
    "    h5file_path = obj_path_dir+\"/loop.geoh5\"\n",
    "\n",
    "    workspace = Workspace(h5file_path)\n",
    "    onlyfiles = [f for f in listdir(obj_path_dir) if isfile(join(obj_path_dir, f))]\n",
    "    colour_index=0\n",
    "    all_sorts = pd.read_csv(os.path.join(colour_path, 'all_sorts_clean.csv'), \",\")\n",
    "    all_sorts=all_sorts.set_index('code')\n",
    "    colour_map=open(obj_path_dir+'/loop_colour_map.clr','w')\n",
    "    colour_map.write('{\\tStart\\tRed\\tGreen\\tBlue\\t}\\n')\n",
    "\n",
    "    for file in onlyfiles:\n",
    "        if ('.obj' in file):\n",
    "            obj=pd.read_csv(obj_path_dir+'/'+file,' ',names=[\"code\",\"X\",\"Y\",\"Z\"])\n",
    "            indices=obj[obj['code']=='f']\n",
    "            vertices=obj[obj['code']=='v']\n",
    "            vertices=vertices.drop(['code'], axis=1)\n",
    "            indices=indices[list(\"XYZ\")].astype(int)\n",
    "            i=indices.to_numpy()-1\n",
    "            v=vertices.to_numpy()\n",
    "            if(len(i)>0 and len(v)>0):\n",
    "                # Create a geoh5 surface\n",
    "                surface = Surface.create(\n",
    "                          workspace, name=file.replace('.obj',''), vertices=v, cells=i\n",
    "                            )\n",
    "                if('Fault_' in file or 'dtm' in file):\n",
    "                    colours=np.ones(surface.n_cells)*99\n",
    "                else:\n",
    "                    colours=np.ones(surface.n_cells)*colour_index\n",
    "                    rgb=hextofloats(all_sorts.loc[file.replace('.obj','')]['colour'])\n",
    "                    colour_map.write('{}\\t{}\\t{}\\t{}\\n'.format(colour_index,rgb[0],rgb[1],rgb[2]))\n",
    "                    colour_index=colour_index+1\n",
    "                    \n",
    "\n",
    "                surface.add_data({\n",
    "                    \"colour_index\": {\n",
    "                        \"association\":\"CELL\",\n",
    "                        \"values\": colours\n",
    "                    }\n",
    "                })\n",
    "                \n",
    "                workspace.save_entity(surface)\n",
    "                workspace.finalize()\n",
    "                \n",
    "    colour_map.write('{}\\t{}\\t{}\\t{}\\n'.format(99,1,1,1))\n",
    "    colour_map.close()\n",
    "    print(\"colour map saved as:\",obj_path_dir+'/loop_colour_map.clr')\n",
    "\n",
    "obj_path_dir= 'C:/Users/mark/Desktop/july_models/model5_m/model5_m/'   # directory of existing obj surfaces\n",
    "colour_path='C:/Users/mark/Desktop/july_models/model5_m/tmp/'\n",
    "geoh5_create_surface_data(obj_path_dir,colour_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d01005a",
   "metadata": {},
   "source": [
    "### dxf format surfaces from directory of obj files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fadfda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to parse a directory of .obj files and combine them into\n",
    "#a single 3D DXF file that Micromine, Datamine, Vulcan... can read\n",
    "#(note .dxf meshes are 1 based)\n",
    "#Run this code after obj files have been created (see Example notebooks)\n",
    "\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "\n",
    "def dxf_create_surface_data(obj_path_dir):\n",
    "\n",
    "\n",
    "    onlyfiles = [f for f in listdir(obj_path_dir) if isfile(join(obj_path_dir, f))]\n",
    "    \n",
    "    fout = open(obj_path_dir+'/loop.dxf', \"w\")\n",
    "    fout.write(\"  0\\nSECTION\\n  2\\nENTITIES\\n\")\n",
    "\n",
    "    for file in onlyfiles:\n",
    "        if ('.obj' in file):\n",
    "            obj=pd.read_csv(obj_path_dir+'/'+file,' ',names=[\"code\",\"X\",\"Y\",\"Z\"])\n",
    "            indices=obj[obj['code']=='f']\n",
    "            vertices=obj[obj['code']=='v']\n",
    "            vertices=vertices.drop(['code'], axis=1)\n",
    "            indices=indices[list(\"XYZ\")].astype(int)\n",
    "            i=indices.to_numpy()-1\n",
    "            v=vertices.to_numpy()\n",
    "           \n",
    "            if(len(i)>0 and len(v)>0):\n",
    "                for ind in range(0, i.shape[0]):\n",
    "                    triangle=\"  0\\n3DFACE\\n  8\\n{}\\n  10\\n{}\\n  20\\n{}\\n  30\\n{}\\n  11\\n{}\\n  21\\n{}\\n  31\\n{}\\n  12\\n{}\\n  22\\n{}\\n  32\\n{}\\n  13\\n{}\\n  23\\n{}\\n  33\\n{}\\n\".format(\n",
    "                                file.replace('.obj',''),v[i[ind,0],0], v[i[ind,0],1], v[i[ind,0],2]\n",
    "                                                        ,v[i[ind,1],0], v[i[ind,1],1], v[i[ind,1],2]\n",
    "                                                        ,v[i[ind,2],0], v[i[ind,2],1], v[i[ind,2],2]\n",
    "                                                        ,v[i[ind,2],0], v[i[ind,2],1], v[i[ind,2],2])\n",
    "                    fout.write(triangle)\n",
    "  \n",
    "    fout.write(\"0\\nENDSEC\\n  0\\nEOF\\n\")\n",
    "    fout.write(\"END\\n\")\n",
    "    fout.close()\n",
    "\n",
    "            \n",
    "#obj_path_dir= './Example2/vtkleaflet_2021-07-16-09-43/'   # directory of existing obj surfaces\n",
    "dxf_create_surface_data(obj_path_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5378c127",
   "metadata": {},
   "source": [
    "### Gocad ts format surfaces from directory of obj files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d9bdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to parse a directory of .obj files and combine them into\n",
    "#a set of Gocad .ts files that GeoscienceAnalyst and Gocad can read\n",
    "#(note .ts meshes are 1 based)\n",
    "#Run this code after obj files have been created (see Example notebooks)\n",
    "\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "\n",
    "def gocad_create_surface_data(obj_path_dir):\n",
    "\n",
    "\n",
    "    onlyfiles = [f for f in listdir(obj_path_dir) if isfile(join(obj_path_dir, f))]\n",
    "    \n",
    "    for file in onlyfiles:\n",
    "        if ('.obj' in file):\n",
    "            obj=pd.read_csv(obj_path_dir+'/'+file,' ',names=[\"code\",\"X\",\"Y\",\"Z\"])\n",
    "            indices=obj[obj['code']=='f']\n",
    "            vertices=obj[obj['code']=='v']\n",
    "            vertices=vertices.drop(['code'], axis=1)\n",
    "            indices=indices[list(\"XYZ\")].astype(int)\n",
    "            i=indices.to_numpy()\n",
    "            v=vertices.to_numpy()\n",
    "            \n",
    "            if(len(i)>0 and len(v)>0): \n",
    "                fout = open(obj_path_dir+'/'+file.replace('.obj','')+'.ts', \"w\")\n",
    "                #fout.write(\"GOCAD Tsurf 1 \\nHEADER {\\nname:\" + file.replace('.obj','') + \"\\n}\\nTFACE\\n\")\n",
    "                fout.write(\"GOCAD TSurf 1\\nHEADER {\\nname:\"+\n",
    "                        file.replace('.obj','')+\n",
    "                        \"\\n}\\nTFACE\\n\")\n",
    "\n",
    "                for ind in range(0, v.shape[0]):\n",
    "                    fout.write(\"PVRTX %d %f %f %f\\n\" % (ind + 1, v[ind,0], v[ind,1], v[ind,2]))\n",
    "\n",
    "                for ind in range(0,i.shape[0]):\n",
    "                    fout.write(\"TRGL %d %d %d\\n\" % (i[ind,0], i[ind,1], i[ind,2]))\n",
    "\n",
    "\n",
    "                fout.write(\"END\\n\")\n",
    "                fout.close()\n",
    "\n",
    "            \n",
    "#obj_path_dir= './Example2/vtkleaflet_2021-07-16-09-43/'   # directory of existing obj surfaces\n",
    "gocad_create_surface_data(obj_path_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60211c1e",
   "metadata": {},
   "source": [
    "### Open Mining Format omf format surfaces from directory of obj files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f09e8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to parse a directory of .obj files and combine them into\n",
    "#a single 3D OMF file that Micromine, Datamine, Vulcan... can read\n",
    "#(note .omf meshes are 1 based) \n",
    "# requires pip install omf (and omfvista and  ipyvtklink if you want to visualise them)\n",
    "# https://omf.readthedocs.io/en/latest/content/examples.html\n",
    "# https://gmggroup.org/projects/data-exchange-for-mine-software/\n",
    "# https://github.com/gmggroup/omf\n",
    "#Run this code after obj files have been created (see Example notebooks)\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import omf\n",
    "import random\n",
    "import pandas as pd\n",
    "import copy\n",
    "def hextoints(h):\n",
    "    '''Takes a hex rgb string (e.g. #ffffff) and returns an RGB tuple (float, float, float).'''\n",
    "    return tuple(int(h[i:i + 2], 16) for i in (1, 3, 5))\n",
    "\n",
    "def omf_create_surface_data(obj_path_dir,colour_path):\n",
    "\n",
    "    proj = omf.Project(\n",
    "        name='Loop project',\n",
    "        description='Bunch of surfaces'\n",
    "    )\n",
    "\n",
    "    onlyfiles = [f for f in listdir(obj_path_dir) if isfile(join(obj_path_dir, f))]\n",
    "\n",
    "    all_sorts = pd.read_csv(os.path.join(colour_path, 'all_sorts_clean.csv'), \",\")\n",
    "    all_sorts=all_sorts.set_index('code')\n",
    "    colour_map=open(obj_path_dir+'/loop_colour_map.clr','w')\n",
    "    colour_map.write('{\\tStart\\tRed\\tGreen\\tBlue\\t}\\n')\n",
    "    \n",
    "    surfaces=[]\n",
    "    for file in onlyfiles:\n",
    "        if ('.obj' in file):\n",
    "\n",
    "            obj=pd.read_csv(obj_path_dir+'/'+file,' ',names=[\"code\",\"X\",\"Y\",\"Z\"])\n",
    "            indices=obj[obj['code']=='f']\n",
    "            vertices=obj[obj['code']=='v']\n",
    "            vertices=vertices.drop(['code'], axis=1)\n",
    "            indices=indices[list(\"XYZ\")].astype(int)\n",
    "            i=indices.to_numpy()-1\n",
    "            v=vertices.to_numpy()\n",
    "            i=np.ascontiguousarray(i)\n",
    "            v=np.ascontiguousarray(v)\n",
    "            \n",
    "            if('Fault_' in file or 'dtm' in file):\n",
    "                rgb=255,255,255\n",
    "            else:\n",
    "                rgb=hextoints(all_sorts.loc[file.replace('.obj','')]['colour'])\n",
    "\n",
    "            if(len(i)>0 and len(v)>0):\n",
    "                surf = omf.SurfaceElement(\n",
    "                    name=file.replace('.obj',''),\n",
    "                    geometry=omf.SurfaceGeometry(\n",
    "                        vertices=v,\n",
    "                        triangles=i\n",
    "                    ),\n",
    "                    data=[\n",
    "                        omf.ScalarData(\n",
    "                            name='rand vert data',\n",
    "                            array=np.random.rand(v.shape[0]),\n",
    "                            location='vertices'\n",
    "                        ),\n",
    "                        omf.ScalarData(\n",
    "                            name='rand face data',\n",
    "                            array=np.random.rand(i.shape[0]),\n",
    "                            location='faces'\n",
    "                        )\n",
    "                        ],           \n",
    "                    color=[rgb[0],rgb[1],rgb[2]]\n",
    "                    )\n",
    "                surfaces.append(copy.deepcopy(surf))\n",
    "\n",
    "    proj.elements = surfaces\n",
    "\n",
    "    assert proj.validate()\n",
    "    \n",
    "    omf.OMFWriter(proj, obj_path_dir+'/loop_surf.omf')\n",
    "\n",
    "            \n",
    "obj_path_dir= './Example2/vtkleaflet_2021-07-16-09-43/'   # directory of existing obj surfaces\n",
    "colour_path='./Example2/tmp/'\n",
    "omf_create_surface_data(obj_path_dir,colour_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca6c3fa",
   "metadata": {},
   "source": [
    "### GeoscienceAnalyst geohy5 format voxel model from LoopStructural  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21032bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to take a LoopStructural voxel model and save it out\n",
    "#as a *.geoh5 GeoscienceAnalyst model \n",
    "#weird indexing because default LS block has X & Y swapped & Z -ve\n",
    "#assumes model already created by LoopStructural, and minx, maxx info from main calculations\n",
    "#Requires installation of https://github.com/MiraGeoscience/geoh5py \n",
    "\n",
    "# assumes LoopStructural model object has been calculated\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from geoh5py.objects import BlockModel\n",
    "from geoh5py.workspace import Workspace\n",
    " \n",
    "voxel_size=500\n",
    "sizex=int((maxx-minx)/voxel_size)\n",
    "sizey=int((maxy-miny)/voxel_size)\n",
    "sizez=int((model_top-model_base)/voxel_size)\n",
    "nsteps=[sizex,sizey,sizez]\n",
    "\n",
    "def create_geoh5_block_model_data(model,voxel_size,minx,miny,maxx,maxy,model_base,model_top,output_dir,nsteps):\n",
    "    \n",
    "    voxels=model.evaluate_model(model.regular_grid(nsteps=(nsteps[0],nsteps[1],nsteps[2]),shuffle=False),scale=False)\n",
    "\n",
    "    name = \"MyLoopBlockModel\"\n",
    "\n",
    "    # Generate a 3D array\n",
    "\n",
    "    nodal_y = np.arange(0,maxx-minx+1,voxel_size)\n",
    "    nodal_x = np.arange(0,maxy-miny+1,voxel_size)\n",
    "    nodal_z = np.arange(model_top-model_base+1,0,-voxel_size)\n",
    "\n",
    "    h5file_path = output_dir+\"/loop_block_model.geoh5\"\n",
    "\n",
    "\n",
    "    # Create a workspace\n",
    "    workspace = Workspace(h5file_path)\n",
    "\n",
    "    grid = BlockModel.create(\n",
    "        workspace,\n",
    "        origin=[minx+(voxel_size/2), miny+(voxel_size/2), model_base+(voxel_size/2)],\n",
    "        u_cell_delimiters=nodal_x,\n",
    "        v_cell_delimiters=nodal_y,\n",
    "        z_cell_delimiters=nodal_z,\n",
    "        name=name,\n",
    "        rotation=0,\n",
    "        allow_move=False,\n",
    "    )\n",
    "    data = grid.add_data(\n",
    "        {\n",
    "            \"DataValues\": {\n",
    "                \"association\": \"CELL\",\n",
    "                \"values\": (\n",
    "                    voxels.reshape((nodal_x.shape[0]-1,nodal_y.shape[0]-1,nodal_z.shape[0]-1)).transpose((1,0,2))\n",
    "                ),\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    workspace.save_entity(grid)\n",
    "    workspace.finalize()\n",
    "\n",
    "output_dir= ''   # output directory to save geoh5 format voxel mdoel\n",
    "create_geoh5_block_model_data(model,voxel_size,minx,miny,maxx,maxy,model_base,model_top,output_dir,nsteps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8c31ac",
   "metadata": {},
   "source": [
    "### Open Mining Format omf format voxel model from LoopStructural  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb082bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to take a LoopStructural voxel model and save it out\n",
    "#as a *.omf file that Micromine, Datamine, Vulcan... can read\n",
    "#weird indexing because default LS block has X & Y swapped & Z -ve\n",
    "# requires pip install omf (and omfvista and  ipyvtklink if you want to visualise them)\n",
    "# https://omf.readthedocs.io/en/latest/content/examples.html\n",
    "# https://gmggroup.org/projects/data-exchange-for-mine-software/\n",
    "# https://github.com/gmggroup/omf\n",
    "#assumes model already created by LoopStructural, and minx, maxx info from main calculations\n",
    "\n",
    "# assumes LoopStructural model object has been calculated\n",
    "\n",
    "voxel_size=500\n",
    "sizex=int((maxx-minx)/voxel_size)\n",
    "sizey=int((maxy-miny)/voxel_size)\n",
    "sizez=int((model_top-model_base)/voxel_size)\n",
    "nsteps=[sizex,sizey,sizez]\n",
    "\n",
    "import omf\n",
    "def create_omf_block_model_data(model,voxel_size,minx,miny,maxx,maxy,model_base,model_top,output_dir,colour_path,nsteps):\n",
    "    \n",
    "    voxels=model.evaluate_model(model.regular_grid(nsteps=(nsteps[0],nsteps[1],nsteps[2]),shuffle=False),scale=False)\n",
    "\n",
    "    name = \"MyLoopBlockModel\"\n",
    "\n",
    "    # Generate a 3D array\n",
    "    proj = omf.Project(\n",
    "        name='Loop project',\n",
    "        description='Loop Block Model'\n",
    "    )\n",
    "\n",
    "    nodal_x = int((maxx-minx+1)/voxel_size)\n",
    "    nodal_y = int((maxy-miny+1)/voxel_size)\n",
    "    nodal_z = int((model_top-model_base+1)/voxel_size)\n",
    "    print(nodal_x,nodal_y,nodal_z)\n",
    "    print(minx,maxx,miny,maxy,model_base,model_top,voxel_size)\n",
    "    vol = omf.VolumeElement(\n",
    "        name='vol',\n",
    "        geometry=omf.VolumeGridGeometry(\n",
    "            axis_u=(1,0,0),\n",
    "            axis_v=(0,1,0),\n",
    "            axis_w=(0,0,-1),\n",
    "            tensor_u=np.ones(nodal_y).astype(float)*voxel_size*(nodal_x/nodal_y),\n",
    "            tensor_v=np.ones(nodal_x).astype(float)*voxel_size*(nodal_y/nodal_x),\n",
    "            tensor_w=np.ones(nodal_z).astype(float)*voxel_size,\n",
    "            origin=[minx-(voxel_size/2),miny-(voxel_size/2),model_base-(voxel_size/2)]\n",
    "        ),\n",
    "        data=[\n",
    "            omf.ScalarData(\n",
    "                name='LithoData',\n",
    "                location='cells',\n",
    "                array=voxels.reshape((nodal_z,nodal_x,nodal_y)).transpose((0,1,2)).flatten()\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    proj.elements = [vol]\n",
    "\n",
    "    assert proj.validate()\n",
    "    \n",
    "    omf.OMFWriter(proj, output_dir+'/loop_block.omf')\n",
    "\n",
    "output_dir= ''   # output directory to save omf format voxel mdoel\n",
    "colour_path='./Example2/tmp/'\n",
    "\n",
    "create_omf_block_model_data(model,voxel_size,minx,miny,maxx,maxy,model_base,model_top,output_dir,colour_path,nsteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0ac119",
   "metadata": {},
   "source": [
    "### Export model as gocad voxet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d60197",
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_size=500\n",
    "sizex=int((maxx-minx)/voxel_size)\n",
    "sizey=int((maxy-miny)/voxel_size)\n",
    "sizez=int((model_top-model_base)/voxel_size)\n",
    "\n",
    "nsteps=[sizex,sizey,sizez]\n",
    "output_dir= ''   # output directory to save omf format voxel mdoel\n",
    "file_name='loop_voxels'\n",
    "data_label='lithoindex'\n",
    "\n",
    "\n",
    "def write_vol_gocad(model, file_path,file_name, data_label, nsteps, real_coords=True):\n",
    "    \"\"\"\n",
    "    Writes out the model as a 3d volume grid in GOCAD VOXET object format\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : GeologicalModel object\n",
    "        Geological model to export\n",
    "    file_name : string\n",
    "        Name of file that model is exported to, including path, but without the file extension\n",
    "    data_label : string\n",
    "        A data label to insert into export file\n",
    "    nsteps : np.array([num-x-steps, num-y-steps, num-z-steps])\n",
    "        3d array dimensions\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    True if successful\n",
    "\n",
    "    \"\"\"\n",
    "    # Define grid spacing in model scale coords\n",
    "    loop_X = np.linspace(model.bounding_box[0, 0], model.bounding_box[1, 0], nsteps[0])\n",
    "    loop_Y = np.linspace(model.bounding_box[0, 1], model.bounding_box[1, 1], nsteps[1])\n",
    "    loop_Z = np.linspace(model.bounding_box[0, 2], model.bounding_box[1, 2], nsteps[2])\n",
    "\n",
    "    # Generate model values in 3d grid\n",
    "    xx, yy, zz = np.meshgrid(loop_X, loop_Y, loop_Z, indexing='ij')\n",
    "    # xyz is N x 3 vector array\n",
    "    xyz = np.array([xx.flatten(), yy.flatten(), zz.flatten()]).T\n",
    "    vals = model.evaluate_model(xyz, scale=False)\n",
    "    # Use FORTRAN style indexing for GOCAD VOXET\n",
    "    vol_vals = np.reshape(vals, nsteps, order='F')\n",
    "    bbox = model.bounding_box[:]\n",
    "        \n",
    "    # Convert bounding box to real world scale coords\n",
    "    if real_coords:\n",
    "        model.rescale(np.int64)\n",
    "    print(type(vals[0]))\n",
    "    # If integer values\n",
    "    if (type(vals[0]) is np.int64 or type(vals[0]) is np.int32 ):\n",
    "        d_type = np.int8\n",
    "        no_data_val = None\n",
    "        prop_esize = 1\n",
    "        prop_storage_type = \"Octet\"\n",
    "\n",
    "    # If float values\n",
    "    elif type(vals[0]) is np.float32:\n",
    "        d_type = np.dtype('>f4')\n",
    "        no_data_val = -999999.0\n",
    "        prop_esize = 4\n",
    "        prop_storage_type = \"Float\"\n",
    "    else:\n",
    "        print(\"Cannot export volume to GOCAD VOXET file: Unsupported type {}\".format(type(vals[0])))\n",
    "        return False\n",
    "\n",
    "    # Write out VOXET file\n",
    "    vo_filename = file_name + \".vo\"\n",
    "    data_filename = file_name + \"@@\"\n",
    "    try:\n",
    "        with open(file_path+vo_filename, \"w\") as fp:\n",
    "            fp.write(\"\"\"GOCAD Voxet 1\n",
    "HEADER {{\n",
    "name: {name}\n",
    "}}\n",
    "AXIS_O 0.000000 0.000000 0.000000\n",
    "AXIS_U 1.000000 0.000000 0.000000\n",
    "AXIS_V 0.000000 1.000000 0.000000\n",
    "AXIS_W 0.000000 0.000000 1.000000\n",
    "AXIS_MIN {axismin1} {axismin2} {axismin3}\n",
    "AXIS_MAX {axismax1} {axismax2} {axismax3}\n",
    "AXIS_N {nsteps1} {nsteps2} {nsteps3}\n",
    "AXIS_D {xdim} {ydim} {zdim}\n",
    "AXIS_NAME \"X\" \"Y\" \"Z\"\n",
    "AXIS_UNIT \"m\" \"m\" \"m\"\n",
    "AXIS_TYPE even even even\n",
    "PROPERTY 1 {propname}\n",
    "PROPERTY_CLASS 1 {propname}\n",
    "PROP_UNIT 1 {propname}\n",
    "PROPERTY_CLASS_HEADER 1 {propname} {{\n",
    "}}\n",
    "PROPERTY_SUBCLASS 1 QUANTITY {prop_storage_type}\n",
    "\"\"\".format(name=os.path.basename(file_name),\n",
    "                nsteps1=nsteps[0], nsteps2=nsteps[1], nsteps3=nsteps[2],\n",
    "                axismin1=bbox[0, 0], axismin2=bbox[0, 1], axismin3=bbox[0, 2],\n",
    "                axismax1=bbox[1, 0], axismax2=bbox[1, 1], axismax3=bbox[1, 2],\n",
    "                propname=data_label, prop_storage_type=prop_storage_type,\n",
    "                xdim=(bbox[0, 0]-bbox[1, 0])/nsteps[0],\n",
    "                ydim=(bbox[0, 1]-bbox[1, 1])/nsteps[1],\n",
    "                zdim=(bbox[0, 2]-bbox[1, 2])/nsteps[2]))\n",
    "            if no_data_val is not None:\n",
    "                fp.write(\"PROP_NO_DATA_VALUE 1 {no_data_val}\\n\".format(no_data_val=no_data_val))\n",
    "            fp.write(\"\"\"PROP_ETYPE 1 IEEE\n",
    "PROP_FORMAT 1 RAW\n",
    "PROP_ESIZE 1 {prop_esize}\n",
    "PROP_OFFSET 1 0\n",
    "PROP_FILE 1 {prop_file}\n",
    "END\\n\"\"\".format(prop_file=data_filename, prop_esize=prop_esize))\n",
    "    except IOError as exc:\n",
    "        print(\"Cannot export volume to GOCAD VOXET file {}: {}\".format(vo_filename, str(exc)))\n",
    "        return False\n",
    "\n",
    "    # Write out accompanying binary data file\n",
    "    export_vals = np.array(vol_vals, dtype=d_type)\n",
    "    try:\n",
    "        with open(file_path+data_filename, \"wb\") as fp:\n",
    "            export_vals.tofile(fp)\n",
    "    except IOError as exc:\n",
    "        print(\"Cannot export volume to GOCAD VOXET data file {}: {}\".format(data_filename, str(exc)))\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "write_vol_gocad(model, output_dir,file_name, data_label, nsteps, real_coords=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241547e7",
   "metadata": {},
   "source": [
    "## Extract all information from Loop gml file\n",
    "\n",
    "### Extract Loop gml data from nodes as pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaf81c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datatypes with topology\n",
    "# ntype from   'fault' \n",
    "#              'formation' \n",
    "#              'group' \n",
    "#              'supergroup' \n",
    "# returns a pandas dataframe\n",
    "\n",
    "\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "def get_nodes_from_graph(Gloop,ntype):\n",
    "\n",
    "    nodes_all=[]\n",
    "    for v in Gloop.nodes():\n",
    "        if(Gloop.nodes[v]['ntype']==ntype):\n",
    "            nodes_all.append(v)\n",
    "    nodes=Gloop.subgraph(nodes_all)\n",
    "    data=pd.DataFrame.from_dict(dict(nodes.nodes(data=True)), orient='index')\n",
    "    data['name']=data.index\n",
    "    if(ntype=='fault'):\n",
    "        columns={'ntype': 'ntype', 'Xmean': 'Xmean', 'Ymean': 'Ymean', 'Zmean': 'Zmean', 'HorizontalRadius': 'HzRad', 'VerticalRadius': 'Vrad', 'InfluenceDistance': 'NDist', \n",
    "             'IncLength': 'IncLength', 'f_colour': 'colour', 'Dip': 'Dip_1', 'DipDirection': 'DipDir', 'DipPolarity': 'Polarity', \n",
    "             'OrientationCluster': 'OCluster', 'LengthCluster': 'LCluster', 'ClosenessCentrality': 'CCentral', 'BetweennessCentrality':'BCentral'}\n",
    "    elif(ntype=='formation'):\n",
    "        columns={'ntype': 'ntype', 'label': 'label', 's_colour': 's_colour', 'group': 'group', 'StratType': 'StratType', 'uctype': 'uctype', 'GroupNum': 'GroupNumber', \n",
    "             'IndexInGp': 'IndexInGroup', 'NumberInGp': 'NumberInGroup', 'ThMedian': 'ThicknessMedian', 'ThStd': 'ThicknessStd', 'ThMethod': 'ThicknessMethod'}\n",
    "    elif(ntype=='group' or ntype=='supergroup'):\n",
    "        columns={'ntype': 'ntype', 'label': 'label', 's_colour': 's_colour', 'group': 'group', 'StratType': 'StratType', 'uctype': 'uctype', 'GroupNum': 'GroupNumber', \n",
    "             'IndexInGp': 'IndexInGroup', 'NumberInGp': 'NumberInGroup', 'ThMedian': 'ThicknessMedian', 'ThStd': 'ThicknessStd', 'ThMethod': 'ThicknessMethod'}\n",
    "    data=data.rename(columns =columns, inplace = False)\n",
    "    return(data)\n",
    "\n",
    "Gloop=nx.read_gml('Example2/output/loop_colour.gml')\n",
    "display(get_nodes_from_graph(Gloop,'fault'),\n",
    "get_nodes_from_graph(Gloop,'formation'),\n",
    "get_nodes_from_graph(Gloop,'supergroup'),\n",
    "get_nodes_from_graph(Gloop,'group'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d813497",
   "metadata": {},
   "source": [
    "### Extract geolocated point data from graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ae6513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datatypes with xyz but no topology\n",
    "# dataype from 'fault_geom' \n",
    "#              'fault_displacement' \n",
    "#              'fault_strat_displacement' \n",
    "#              'contact' \n",
    "#              'orientation'\n",
    "#              'raw_contact'\n",
    "# returns a pandas dataframe\n",
    "\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "def get_point_data_from_graph(Gloop,datatype):\n",
    "\n",
    "    nodes_all=[]\n",
    "    for v in Gloop.nodes():\n",
    "        if(Gloop.nodes[v]['ntype']=='points'):\n",
    "            data=Gloop.nodes[v]['data']\n",
    "    df = pd.DataFrame()\n",
    "    if(datatype=='fault_geom'):\n",
    "        Param1='Param1'\n",
    "        Param2='Param2'\n",
    "        Param3='Param3'\n",
    "        Param4='Param4'\n",
    "    elif(datatype=='fault_displacement'):\n",
    "        Param1='HzRad'\n",
    "        Param2='Vrad'\n",
    "        Param3='NDist'\n",
    "        Param4='Param4'\n",
    "    elif(datatype=='fault_strat_displacement'):\n",
    "        Param1='left_fm'\n",
    "        Param2='right_fm'\n",
    "        Param3='min_offset'\n",
    "        Param4='strat_offset'\n",
    "    elif(datatype=='contact'):\n",
    "        Param1='Param1'\n",
    "        Param2='Param2'\n",
    "        Param3='Param3'\n",
    "        Param4='Param4'\n",
    "    elif(datatype=='orientation'):\n",
    "        Param1='OCluster'\n",
    "        Param2='LCluster'\n",
    "        Param3='CCentral'\n",
    "        Param4='BCentral'\n",
    "    elif(datatype=='raw_contact'):\n",
    "        Param1='group'\n",
    "        Param2='angle'\n",
    "        Param3='lsx'\n",
    "        Param4='lsy'\n",
    "        \n",
    "    for d in data:\n",
    "        if(d['type']==datatype):\n",
    "            df = df.append({  'type': d['type'],\n",
    "                              'name': d['name'],\n",
    "                              'X': d['X'],\n",
    "                              'Y': d['Y'],\n",
    "                              'Z': d['Z'],\n",
    "                              Param1:d['Param1'],\n",
    "                              Param2:d['Param2'],\n",
    "                              Param3:d['Param3'],\n",
    "                              Param4:d['Param4']\n",
    "                           }, ignore_index=True)\n",
    "    return(df)\n",
    "\n",
    "Gloop=nx.read_gml('Example2/output/loop.gml')\n",
    "display(get_point_data_from_graph(Gloop,'fault_geom'),\n",
    "       get_point_data_from_graph(Gloop,'fault_displacement'),\n",
    "       get_point_data_from_graph(Gloop,'fault_strat_displacement'),\n",
    "       get_point_data_from_graph(Gloop,'contact'),\n",
    "       get_point_data_from_graph(Gloop,'orientation'),\n",
    "       get_point_data_from_graph(Gloop,'raw_contact'))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d783b7fc",
   "metadata": {},
   "source": [
    "### Extract DTM grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bc4023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract dtm grid\n",
    "# returns a numpy array\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "def get_dtm_from_graph(Gloop):\n",
    "\n",
    "    nodes_all=[]\n",
    "    for v in Gloop.nodes():\n",
    "        if(Gloop.nodes[v]['ntype']=='dtm'):\n",
    "            data=Gloop.nodes[v]['data']\n",
    "            shape=Gloop.nodes[v]['shape']\n",
    "            minx=Gloop.nodes[v]['minx']\n",
    "            miny=Gloop.nodes[v]['miny']\n",
    "            maxx=Gloop.nodes[v]['maxx']\n",
    "            maxy=Gloop.nodes[v]['maxy']\n",
    "            xscale=Gloop.nodes[v]['xscale']\n",
    "            yscale=Gloop.nodes[v]['yscale']\n",
    "\n",
    "            dtm=np.array(data.replace('[','').replace(']','').split(','), dtype=np.float32)\n",
    "            shape=shape.replace('(','').replace(')','').split(',')\n",
    "            x=int(shape[0])\n",
    "            y=int(shape[1])\n",
    "            dtm=dtm.reshape(x,y)\n",
    "    return(minx,miny,maxx,maxy,xscale,yscale,dtm)        \n",
    "\n",
    "Gloop=nx.read_gml('Example2/output/loop.gml')\n",
    "display(get_dtm_from_graph(Gloop))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a58e5c",
   "metadata": {},
   "source": [
    "### extract bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7a5763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract bbox grid\n",
    "# returns a numpy array\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "def get_bbox_from_graph(Gloop):\n",
    "\n",
    "    nodes_all=[]\n",
    "    for v in Gloop.nodes():\n",
    "        if(Gloop.nodes[v]['ntype']=='bbox'):\n",
    "            data=Gloop.nodes[v]['data']\n",
    "            bbox=np.array(data.replace('[','').replace(']','').split(','), dtype=np.float32)\n",
    "    return(bbox)        \n",
    "\n",
    "Gloop=nx.read_gml('Example2/output/loop.gml')\n",
    "display(get_bbox_from_graph(Gloop))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da6f6f5",
   "metadata": {},
   "source": [
    "### Extract crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1652643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract dst_crs grid\n",
    "# returns a string\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "def get_dst_crs_from_graph(Gloop):\n",
    "\n",
    "    nodes_all=[]\n",
    "    for v in Gloop.nodes():\n",
    "        if(Gloop.nodes[v]['ntype']=='dst_crs'):\n",
    "            data=Gloop.nodes[v]['data']\n",
    "    return(data)        \n",
    "\n",
    "Gloop=nx.read_gml('Example2/output/loop.gml')\n",
    "display(get_dst_crs_from_graph(Gloop))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e69706",
   "metadata": {},
   "source": [
    "### Extract map2loop runtime metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc750561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract dst_crs grid\n",
    "# returns three strings\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "def get_metadata_from_graph(Gloop):\n",
    "\n",
    "    nodes_all=[]\n",
    "    for v in Gloop.nodes():\n",
    "        if(Gloop.nodes[v]['ntype']=='metadata'):\n",
    "            run_flags=Gloop.nodes[v]['run_flags']\n",
    "            c_l=Gloop.nodes[v]['c_l']\n",
    "            config=Gloop.nodes[v]['config']\n",
    "    return(c_l,run_flags,config)        \n",
    "\n",
    "Gloop=nx.read_gml('Example2/output/loop.gml')\n",
    "c_l,run_flags,config=get_metadata_from_graph(Gloop)\n",
    "display(\"c_l\",c_l,\"run_flags\",run_flags,\"config\",config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8715c8f2",
   "metadata": {},
   "source": [
    "### Extract subgraph based on node type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5812e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datatypes with xyz but no topology\n",
    "# ntype from   'fault' \n",
    "#              'supergroup' \n",
    "#              'group' \n",
    "#              'formation' \n",
    "# returns a networkx graph\n",
    "\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "def get_subgraph_from_graph_nodes(Gloop,gtype):\n",
    "    nodes_all=[]\n",
    "    for v in Gloop.nodes():\n",
    "        if(Gloop.nodes[v]['ntype']==gtype):\n",
    "            nodes_all.append(v)\n",
    "    subgraph=Gloop.subgraph(nodes_all)\n",
    "    return(subgraph)\n",
    "\n",
    "Gloop=nx.read_gml('Example2/output/loop.gml')\n",
    "subgraph=get_subgraph_from_graph_nodes(Gloop,'fault')\n",
    "nx.draw(subgraph,pos=nx.kamada_kawai_layout(subgraph),with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77e2ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph=get_subgraph_from_graph_nodes(Gloop,'formation')\n",
    "nx.draw(subgraph,pos=nx.kamada_kawai_layout(subgraph),with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e73250",
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph=get_subgraph_from_graph_nodes(Gloop,'group')\n",
    "nx.draw(subgraph,pos=nx.kamada_kawai_layout(subgraph),with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c584d876",
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph=get_subgraph_from_graph_nodes(Gloop,'supergroup')\n",
    "nx.draw(subgraph,pos=nx.kamada_kawai_layout(subgraph),with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14fb307",
   "metadata": {},
   "source": [
    "### Extract subgraph based on edge type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7ef858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datatypes with topology\n",
    "# etype from   'fault_fault' \n",
    "#              'fault_group' \n",
    "#              'group_formation' \n",
    "#              'supergroup_group' \n",
    "#              'group_group'\n",
    "# returns a networkx graph\n",
    "\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "def get_subgraph_from_graph_edges(Gloop,etype):\n",
    "    edges_all=[]\n",
    "    for v in Gloop.edges:\n",
    "        if(Gloop.edges[v]['etype']==etype):\n",
    "            edges_all.append(v)\n",
    "    subgraph=nx.Graph().to_directed()\n",
    "    for e in edges_all:\n",
    "        subgraph.add_edge(e[0],e[1])\n",
    "    return(subgraph)\n",
    "\n",
    "Gloop=nx.read_gml('Example2/output/loop.gml')\n",
    "subgraph=get_subgraph_from_graph_edges(Gloop,'fault_fault')\n",
    "nx.draw(subgraph,pos=nx.kamada_kawai_layout(subgraph),with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f3a1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph=get_subgraph_from_graph_edges(Gloop,'fault_group')\n",
    "nx.draw(subgraph,pos=nx.kamada_kawai_layout(subgraph),with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa912174",
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph=get_subgraph_from_graph_edges(Gloop,'group_formation')\n",
    "nx.draw(subgraph,pos=nx.kamada_kawai_layout(subgraph),with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d10f625",
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph=get_subgraph_from_graph_edges(Gloop,'supergroup_group')\n",
    "nx.draw(subgraph,pos=nx.kamada_kawai_layout(subgraph),with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c3b8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph=get_subgraph_from_graph_edges(Gloop,'group_group')\n",
    "nx.draw(subgraph,pos=nx.kamada_kawai_layout(subgraph),with_labels=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
